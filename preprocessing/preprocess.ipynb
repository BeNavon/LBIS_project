{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script will fetch all csv files from the specified directory and preprocess them.   \n",
    "The preprocessing stage will include:   \n",
    "    - Loop through all the csv files for all subjects and trials.\n",
    "    - Remove unlabeled data (start and end of the experiment) \n",
    "    - Reformatting the labels to be sin and cos of the phase variable.   \n",
    "    - Prefilter the data to remove noise (e.g. Moving Average)    \n",
    "    - Splitting the data into windows (by window size and overlap).   \n",
    "    - Normalizing the input data    \n",
    "    - Remove unnecessary columns (e.g. timestamp, foot and trunk imu data)   \n",
    "    - Saving the preprocessed data into a new data npy file based on the inputs provided for the preprocessing stage    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import butter, lfilter, filtfilt\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario parameter settings\n",
    "is_filter = True            # True or False decision variable to filter the IMU data before splitting into windows \n",
    "filter_type = \"causal\"      # causal or non-causal - choose causal for RT applications\n",
    "cutoff = 25                 # cutoff frequency for the filter (Hz)\n",
    "is_normalize = True         # True or False decision variable to normalize the input data after filtering (before windowing) \n",
    "window_size = 400           # Number of samples per window \n",
    "overlap = 200               # Number of samples to overlap between windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_with_label(imu_data: pd.DataFrame, gc_data: pd.DataFrame, window_size=400, overlap=200):\n",
    "    \"\"\" \n",
    "    Perform sliding window on IMU data and extract the last value of GC data as label.\n",
    "    \n",
    "    Parameters:\n",
    "    - imu_data: DataFrame with 12 columns (IMU channels)\n",
    "    - gc_data: DataFrame with 2 columns (labels)\n",
    "    - window_size: Number of samples per window\n",
    "    - overlap: Number of overlapping samples\n",
    "\n",
    "    Returns:\n",
    "    - X_windows: NumPy array of shape (num_windows, 12, window_size)\n",
    "    - y_labels: NumPy array of shape (num_windows, 2)\n",
    "    \"\"\"\n",
    "    step_size = window_size - overlap\n",
    "    X_windows, y_labels = [], []\n",
    "\n",
    "    for start_idx in range(0, imu_data.shape[0] - window_size + 1, step_size):\n",
    "        end_idx = start_idx + window_size\n",
    "        X_windows.append(imu_data.iloc[start_idx:end_idx].values.T)  # (12, window_size)\n",
    "        y_labels.append(gc_data.iloc[end_idx - 1].values)  # Correctly extract both columns\n",
    "    \n",
    "    return np.array(X_windows), np.array(y_labels)\n",
    "\n",
    "def apply_filter(data, filter_type, cutoff=25, fs=200, order=4):\n",
    "    b, a = butter(order, cutoff / (fs / 2), btype='low', analog=False)\n",
    "    return lfilter(b, a, data, axis=0) if filter_type == \"causal\" else filtfilt(b, a, data, axis=0)\n",
    "\n",
    "def plot_filtered_imu(original_df, filtered_df, channel_idx=0):\n",
    "    plt.plot(original_df.iloc[1:500, channel_idx], label=\"Original\", alpha=0.6)\n",
    "    plt.plot(filtered_df.iloc[1:500, channel_idx], label=\"Filtered\", linestyle=\"--\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.title(f\"IMU Channel {original_df.columns[channel_idx]} Before & After Filtering\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'C:\\Users\\Elad\\vscode Projects\\Technion\\LBIS_project\\dataset'\n",
    "\n",
    "# create a multidimensional array to store the data in one single file\n",
    "X_data = np.empty((0, 12, window_size))\n",
    "y_data = np.empty((0, 2))\n",
    "\n",
    "# access all subject folders\n",
    "for subject in os.listdir(DATA_PATH):\n",
    "    # access all csv files in the treadmill folder of the subject\n",
    "    for file in os.listdir(os.path.join(DATA_PATH,  subject, 'treadmill', 'imu')):\n",
    "        # read the imu csv file\n",
    "        if file.endswith('.csv'):\n",
    "            imu_df = pd.read_csv(os.path.join(DATA_PATH, subject, 'treadmill', 'imu', file))\n",
    "            gc_df = pd.read_csv(os.path.join(DATA_PATH, subject, 'treadmill', 'gcRight', file))\n",
    "\n",
    "            # remove unnecessary columns\n",
    "            gc_df = gc_df.drop(columns=[\"ToeOff\"])\n",
    "            imu_df = imu_df.drop(columns=['foot_Accel_X', 'foot_Accel_Y', 'foot_Accel_Z', 'foot_Gyro_X', 'foot_Gyro_Y', 'foot_Gyro_Z', 'trunk_Accel_X', 'trunk_Accel_Y', 'trunk_Accel_Z', 'trunk_Gyro_X', 'trunk_Gyro_Y', 'trunk_Gyro_Z'])\n",
    "\n",
    "            # remove the first and last samples that have no proper label defined (until the first Heel Strike occurance + after the last Toe Off occurance)\n",
    "            gc_df = gc_df.loc[gc_df.index[gc_df[\"HeelStrike\"].gt(0)].min() : gc_df.index[gc_df[\"HeelStrike\"] == 100].max()]\n",
    "            imu_df = imu_df[imu_df[\"Header\"].isin(gc_df[\"Header\"])] # remove the rows that are not in the gc data\n",
    "\n",
    "            # Apply the cosine and sine functions to the HeelStrike column\n",
    "            gc_df['cos_gait_phase'] = np.cos(gc_df['HeelStrike'] * 2 * np.pi / 100)\n",
    "            gc_df['sin_gait_phase'] = np.sin(gc_df['HeelStrike'] * 2 * np.pi / 100)\n",
    "            \n",
    "            # remove header and other columns\n",
    "            gc_df.drop(columns=[\"Header\",\"HeelStrike\"], inplace=True)\n",
    "            imu_df.drop(columns=['Header'], inplace=True)\n",
    "\n",
    "            gc_df.reset_index(drop=True, inplace=True)\n",
    "            imu_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            # Apply a filter to the IMU data (choose between a causal and non-causal filter i.e. with phase or zero phase lag filters)\n",
    "            # filter_type = \"causal\" # or \"non-causal\" - defined in the scenario parameters settings section\n",
    "            filtered_df = pd.DataFrame(apply_filter(imu_df.values, filter_type=filter_type, cutoff=25, order=4), columns=imu_df.columns) if is_filter else imu_df\n",
    "\n",
    "            # Normalize the input data (is_normalize = True or False)\n",
    "            filtered_df = (filtered_df - filtered_df.mean()) / filtered_df.std() if is_normalize else filtered_df\n",
    "\n",
    "            # Split the data into windows (by window size and overlap)\n",
    "            X_windows, y_labels = sliding_window_with_label(filtered_df, gc_df, window_size=window_size, overlap=overlap)\n",
    "            \n",
    "            # Concatenate the data to the multidimensional array\n",
    "            X_data = np.concatenate((X_data, X_windows), axis=0)\n",
    "            y_data = np.concatenate((y_data, y_labels), axis=0)\n",
    "            \n",
    "    print(f\"The shape of X_windows is: {X_windows.shape}\")\n",
    "    print(f\"The shape of y_labels is: {y_labels.shape}\")\n",
    "    print(f\"The first window of X_windows is: {X_windows[0]}\")\n",
    "    print(f\"The first label of y_labels is: {y_labels[0]}\")\n",
    "    print(f\"The shape of X_data is: {X_data.shape}\")\n",
    "    print(f\"The shape of y_data is: {y_data.shape}\")\n",
    "    \n",
    "    # plot_filtered_imu(imu_df, filtered_df, channel_idx=0)  # Change channel_idx to plot different channels\n",
    "    # print(gc_df.head())\n",
    "    # print(imu_df.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Get the IMU CSV file path.\n",
    "#         imu_path = self.imu_files[idx]\n",
    "#         # Derive the corresponding gcRight CSV file path by replacing 'imu' with 'gcRight'\n",
    "#         gcRight_path = imu_path.replace(os.sep + 'imu' + os.sep, os.sep + 'gcRight' + os.sep)\n",
    "        \n",
    "#         # Load CSV files (skip the header row)\n",
    "#         imu_data = self._load_csv_file(imu_path)\n",
    "#         gcRight_data = self._load_csv_file(gcRight_path)\n",
    "        \n",
    "#         # Drop the timestamp column (first column)\n",
    "#         imu_data = imu_data[:, 1:]\n",
    "#         gcRight_data = gcRight_data[:, 1:]\n",
    "        \n",
    "#         # Select only shank and thigh channels from IMU data.\n",
    "#         # CSV column order (after dropping timestamp) is:\n",
    "#         # [foot_Accel_X, foot_Accel_Y, foot_Accel_Z,\n",
    "#         #  foot_Gyro_X, foot_Gyro_Y, foot_Gyro_Z,\n",
    "#         #  shank_Accel_X, shank_Accel_Y, shank_Accel_Z,\n",
    "#         #  shank_Gyro_X, shank_Gyro_Y, shank_Gyro_Z,\n",
    "#         #  thigh_Accel_X, thigh_Accel_Y, thigh_Accel_Z,\n",
    "#         #  thigh_Gyro_X, thigh_Gyro_Y, thigh_Gyro_Z,\n",
    "#         #  trunk_Accel_X, trunk_Accel_Y, trunk_Accel_Z,\n",
    "#         #  trunk_Gyro_X, trunk_Gyro_Y, trunk_Gyro_Z]\n",
    "#         # We keep shank (columns 6 to 11) and thigh (columns 12 to 17)\n",
    "#         shank = imu_data[:, 6:12]\n",
    "#         thigh = imu_data[:, 12:18]\n",
    "#         imu_selected = np.concatenate([shank, thigh], axis=1)  # Shape: (N, 12)\n",
    "        \n",
    "#         # Synchronize lengths: truncate all signals to the minimum available length.\n",
    "#         min_length = min(imu_selected.shape[0], gcRight_data.shape[0])\n",
    "#         imu_selected = imu_selected[:min_length, :]\n",
    "#         gcRight_data = gcRight_data[:min_length, :]\n",
    "        \n",
    "#         # Randomly extract a window of fixed length.\n",
    "#         if min_length > self.sequence_length:\n",
    "#             start_idx = random.randint(0, min_length - self.sequence_length)\n",
    "#         else:\n",
    "#             start_idx = 0  # Alternatively, pad shorter sequences.\n",
    "#         end_idx = start_idx + self.sequence_length\n",
    "#         imu_window = imu_selected[start_idx:end_idx, :]  # (sequence_length, 12)\n",
    "        \n",
    "#         # Use the HeelStrike value from gcRight at the center of the window.\n",
    "#         center_idx = start_idx + self.sequence_length // 2\n",
    "#         heel_strike = gcRight_data[center_idx, 0]  # HeelStrike value (0-100)\n",
    "#         # Normalize to [0, 1]\n",
    "#         heel_strike_norm = heel_strike / 100.0\n",
    "#         target = np.array([heel_strike_norm], dtype=np.float32)\n",
    "        \n",
    "#         # Optionally apply a transform; otherwise, convert to torch tensors.\n",
    "#         if self.transform:\n",
    "#             imu_window = self.transform(imu_window)\n",
    "#         else:\n",
    "#             imu_window = torch.tensor(imu_window, dtype=torch.float32)\n",
    "#         target = torch.tensor(target, dtype=torch.float32)\n",
    "        \n",
    "#         return imu_window, target\n",
    "\n",
    "#     def _load_csv_file(self, file_path):\n",
    "#         \"\"\"Loads a CSV file using NumPy (skipping the header row).\"\"\"\n",
    "#         data = np.loadtxt(file_path, delimiter=',', skiprows=1)\n",
    "#         return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARDCODED PARAMETERS\n",
    "BASE_SAMPLING_RATE = 200    # Hz\n",
    "\n",
    "# INPUT PARAMETERS\n",
    "NORMALIZE_FLAG = True       # Normalize the data decision variable\n",
    "WINDOW_SIZE = 2             # seconds\n",
    "WINDOW_OVERLAP = 1          # seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
