{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script will fetch all csv files from the specified directory and preprocess them.   \n",
    "The preprocessing stage will include:   \n",
    "    - Loop through all the csv files for all subjects and trials.\n",
    "    - Remove unlabeled data (start and end of the experiment) \n",
    "    - Reformatting the labels to be sin and cos of the phase variable.   \n",
    "    - Prefilter the data to remove noise (e.g. Moving Average)    \n",
    "    - Splitting the data into windows (by window size and overlap).   \n",
    "    - Normalizing the input data    \n",
    "    - Remove unnecessary columns (e.g. timestamp, foot and trunk imu data)   \n",
    "    - Saving the preprocessed data into a new data npy file based on the inputs provided for the preprocessing stage (test and train).  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter, filtfilt\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario parameter settings\n",
    "# DATA_PATH = r'dataset'\n",
    "# DATA_PATH = r'C:\\Users\\Elad\\vscode Projects\\Technion\\LBIS_project\\dataset'\n",
    "DATA_PATH   = r'C:\\Users\\Elad\\Downloads\\dataset\\dataset'\n",
    "validation_subject = 'AB10' # Subject to be used for validation\n",
    "test_subject = 'AB11'       # Subject to be used for testing\n",
    "is_filter = True            # True or False decision variable to filter the IMU data before splitting into windows \n",
    "filter_type = \"causal\"      # causal or non-causal - choose causal for RT applications\n",
    "cutoff = 25                 # cutoff frequency for the filter (Hz)\n",
    "is_normalize = True         # True or False decision variable to normalize the input data after filtering (before windowing) \n",
    "window_size = 200           # Number of samples per window \n",
    "overlap = 100               # Number of samples to overlap between windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_with_label(imu_data: pd.DataFrame, gc_data: pd.DataFrame, window_size=400, overlap=200):\n",
    "    \"\"\" \n",
    "    Perform sliding window on IMU data and extract the last value of GC data as label.\n",
    "    \n",
    "    Parameters:\n",
    "    - imu_data: DataFrame with 12 columns (IMU channels)\n",
    "    - gc_data: DataFrame with 2 columns (labels)\n",
    "    - window_size: Number of samples per window\n",
    "    - overlap: Number of overlapping samples\n",
    "\n",
    "    Returns:\n",
    "    - X_windows: NumPy array of shape (num_windows, 12, window_size)\n",
    "    - y_labels: NumPy array of shape (num_windows, 2)\n",
    "    \"\"\"\n",
    "    step_size = window_size - overlap\n",
    "    X_windows, y_labels = [], []\n",
    "\n",
    "    for start_idx in range(0, imu_data.shape[0] - window_size + 1, step_size):\n",
    "        end_idx = start_idx + window_size\n",
    "        X_windows.append(imu_data.iloc[start_idx:end_idx].values.T)  # (12, window_size)\n",
    "        y_labels.append(gc_data.iloc[end_idx - 1].values)  # Correctly extract both columns\n",
    "    \n",
    "    return np.array(X_windows), np.array(y_labels)\n",
    "\n",
    "def apply_filter(data, filter_type, cutoff=25, fs=200, order=4):\n",
    "    b, a = butter(order, cutoff / (fs / 2), btype='low', analog=False)\n",
    "    return lfilter(b, a, data, axis=0) if filter_type == \"causal\" else filtfilt(b, a, data, axis=0)\n",
    "\n",
    "def plot_filtered_imu(original_df, filtered_df, channel_idx=0):\n",
    "    plt.plot(original_df.iloc[1:500, channel_idx], label=\"Original\", alpha=0.6)\n",
    "    plt.plot(filtered_df.iloc[1:500, channel_idx], label=\"Filtered\", linestyle=\"--\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.title(f\"IMU Channel {original_df.columns[channel_idx]} Before & After Filtering\")\n",
    "    plt.show()\n",
    "\n",
    "def is_validation_subject(subject_id):\n",
    "    return subject_id == validation_subject\n",
    "\n",
    "def is_test_subject(subject_id):\n",
    "    return subject_id == test_subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Elad\\\\Downloads\\\\dataset\\\\dataset\\\\treadmill\\\\imu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# access all csv files in the treadmill folder of the subject\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtreadmill\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# read the imu csv file\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     13\u001b[0m         imu_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_PATH, subject, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreadmill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimu\u001b[39m\u001b[38;5;124m'\u001b[39m, file))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Elad\\\\Downloads\\\\dataset\\\\dataset\\\\treadmill\\\\imu'"
     ]
    }
   ],
   "source": [
    "if is_normalize:\n",
    "    # Calc the global mean and std for normalization (only on train data to avoid data leakage)\n",
    "    # Loop through all the csv files for all subjects and trials in the test folders\n",
    "    all_train_data = np.zeros((0, 12))\n",
    "    for subject in os.listdir(DATA_PATH):\n",
    "        # Skip validation and test subjects\n",
    "        if is_validation_subject(subject) or is_test_subject(subject):\n",
    "            continue\n",
    "        # access all csv files in the treadmill folder of the subject\n",
    "        for file in os.listdir(os.path.join(DATA_PATH,  subject, 'treadmill', 'imu')):\n",
    "            # read the imu csv file\n",
    "            if file.endswith('.csv'):\n",
    "                imu_df = pd.read_csv(os.path.join(DATA_PATH, subject, 'treadmill', 'imu', file))\n",
    "\n",
    "                # remove unnecessary columns\n",
    "                imu_df = imu_df.drop(columns=['Header','foot_Accel_X', 'foot_Accel_Y', 'foot_Accel_Z', 'foot_Gyro_X', 'foot_Gyro_Y', 'foot_Gyro_Z', 'trunk_Accel_X', 'trunk_Accel_Y', 'trunk_Accel_Z', 'trunk_Gyro_X', 'trunk_Gyro_Y', 'trunk_Gyro_Z'])\n",
    "                \n",
    "                # Apply a filter to the IMU data (choose between a causal and non-causal filter i.e. with phase or zero phase lag filters)\n",
    "                # filter_type = \"causal\" # or \"non-causal\" - defined in the scenario parameters settings section\n",
    "                filtered_df = pd.DataFrame(apply_filter(imu_df.values, filter_type=filter_type, cutoff=25, order=4), columns=imu_df.columns) if is_filter else imu_df\n",
    "                \n",
    "                all_train_data = np.vstack((all_train_data, filtered_df.values))\n",
    "\n",
    "    mean_train = np.mean(all_train_data, axis=0)\n",
    "    std_train = np.std(all_train_data, axis=0)\n",
    "    # print((all_train_data.shape))\n",
    "    # print(mean_train)\n",
    "    # print(std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preallocate a multidimensional array to store all the data for all trials and all subjects in test/train npy file\n",
    "X_data = np.empty((0, 12, window_size))\n",
    "y_data = np.empty((0, 2))\n",
    "X_validation_data = np.empty((0, 12, window_size))\n",
    "y_validation_data = np.empty((0, 2))\n",
    "X_test_data = np.empty((0, 12, window_size))\n",
    "y_test_data = np.empty((0, 2))\n",
    "\n",
    "# access all subject folders\n",
    "for subject in os.listdir(DATA_PATH):\n",
    "    # access all csv files in the treadmill folder of the subject\n",
    "    for file in os.listdir(os.path.join(DATA_PATH,  subject, 'treadmill', 'imu')):\n",
    "        # read the imu csv file\n",
    "        if file.endswith('.csv'):\n",
    "            imu_df = pd.read_csv(os.path.join(DATA_PATH, subject, 'treadmill', 'imu', file))\n",
    "            gc_df = pd.read_csv(os.path.join(DATA_PATH, subject, 'treadmill', 'gcRight', file))\n",
    "\n",
    "            # remove unnecessary columns\n",
    "            gc_df = gc_df.drop(columns=[\"ToeOff\"])\n",
    "            imu_df = imu_df.drop(columns=['foot_Accel_X', 'foot_Accel_Y', 'foot_Accel_Z', 'foot_Gyro_X', 'foot_Gyro_Y', 'foot_Gyro_Z', 'trunk_Accel_X', 'trunk_Accel_Y', 'trunk_Accel_Z', 'trunk_Gyro_X', 'trunk_Gyro_Y', 'trunk_Gyro_Z'])\n",
    "\n",
    "            # remove the first and last samples that have no proper label defined (until the first Heel Strike occurance + after the last Toe Off occurance)\n",
    "            gc_df = gc_df.loc[gc_df.index[gc_df[\"HeelStrike\"].gt(0)].min() : gc_df.index[gc_df[\"HeelStrike\"] == 100].max()]\n",
    "            imu_df = imu_df[imu_df[\"Header\"].isin(gc_df[\"Header\"])] # remove the rows that are not in the gc data\n",
    "\n",
    "            # Apply the cosine and sine functions to the HeelStrike column\n",
    "            gc_df['cos_gait_phase'] = np.cos(gc_df['HeelStrike'] * 2 * np.pi / 100)\n",
    "            gc_df['sin_gait_phase'] = np.sin(gc_df['HeelStrike'] * 2 * np.pi / 100)\n",
    "            \n",
    "            # remove header and other columns\n",
    "            gc_df.drop(columns=[\"Header\",\"HeelStrike\"], inplace=True)\n",
    "            imu_df.drop(columns=['Header'], inplace=True)\n",
    "\n",
    "            gc_df.reset_index(drop=True, inplace=True)\n",
    "            imu_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            # Apply a filter to the IMU data (choose between a causal and non-causal filter i.e. with phase or zero phase lag filters)\n",
    "            # filter_type = \"causal\" # or \"non-causal\" - defined in the scenario parameters settings section\n",
    "            filtered_df = pd.DataFrame(apply_filter(imu_df.values, filter_type=filter_type, cutoff=25, order=4), columns=imu_df.columns) if is_filter else imu_df\n",
    "\n",
    "            # Normalize the input data (is_normalize = True or False)\n",
    "            filtered_df = (filtered_df - mean_train) / std_train if is_normalize else filtered_df\n",
    "\n",
    "            # Split the data into windows (by window size and overlap)\n",
    "            X_windows, y_labels = sliding_window_with_label(filtered_df, gc_df, window_size=window_size, overlap=overlap)\n",
    "            \n",
    "            # Concatenate the data to the multidimensional array according to the train / test / validation\n",
    "            if is_validation_subject(subject):\n",
    "                X_validation_data = np.concatenate((X_validation_data, X_windows), axis=0)\n",
    "                y_validation_data = np.concatenate((y_validation_data, y_labels), axis=0)\n",
    "            elif is_test_subject(subject):                \n",
    "                X_test_data = np.concatenate((X_test_data, X_windows), axis=0)\n",
    "                y_test_data = np.concatenate((y_test_data, y_labels), axis=0)\n",
    "            else:    \n",
    "                X_data = np.concatenate((X_data, X_windows), axis=0)\n",
    "                y_data = np.concatenate((y_data, y_labels), axis=0)\n",
    "            \n",
    "    # print(f\"The shape of X_windows is: {X_windows.shape}\")\n",
    "    # print(f\"The shape of y_labels is: {y_labels.shape}\")\n",
    "    # print(f\"The first window of X_windows is: {X_windows[0]}\")\n",
    "    # print(f\"The first label of y_labels is: {y_labels[0]}\")\n",
    "    # plot_filtered_imu(imu_df, filtered_df, channel_idx=0)  # Change channel_idx to plot different channels\n",
    "    # print(gc_df.head())\n",
    "    # print(imu_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of X_data is: {X_data.shape}\")\n",
    "print(f\"The shape of y_data is: {y_data.shape}\")\n",
    "print(f\"The shape of X_validation_data is: {X_validation_data.shape}\")\n",
    "print(f\"The shape of y_validation_data is: {y_validation_data.shape}\")\n",
    "print(f\"The shape of X_test_data is: {X_test_data.shape}\")\n",
    "print(f\"The shape of y_test_data is: {y_test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the testing and training data into npy files\n",
    "np.save('X_train.npy', X_data)\n",
    "np.save('y_train.npy', y_data)\n",
    "np.save('X_test.npy', X_test_data)\n",
    "np.save('y_test.npy', y_test_data)\n",
    "np.save('X_validation.npy', X_validation_data)\n",
    "np.save('y_validation.npy', y_validation_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
