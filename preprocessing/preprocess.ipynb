{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis script will fetch all csv files from the specified directory and preprocess them.   \\nThe preprocessing stage will include:   \\n    - Loop through all the csv files for all subjects and trials.\\n    - Remove unlabeled data (start and end of the experiment) \\n    - Reformatting the labels to be sin and cos of the phase variable.   \\n    - Prefilter the data to remove noise (e.g. Moving Average)    \\n    - Splitting the data into windows (by window size and overlap).   \\n    - Normalizing the input data    \\n    - Remove unnecessary columns (e.g. timestamp, foot and trunk imu data)   \\n    - Saving the preprocessed data into a new data npy file based on the inputs provided for the preprocessing stage (test and train).  \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script will fetch all csv files from the specified directory and preprocess them.   \n",
    "The preprocessing stage will include:   \n",
    "    - Loop through all the csv files for all subjects and trials.\n",
    "    - Remove unlabeled data (start and end of the experiment) \n",
    "    - Reformatting the labels to be sin and cos of the phase variable.   \n",
    "    - Prefilter the data to remove noise (e.g. Moving Average)    \n",
    "    - Splitting the data into windows (by window size and overlap).   \n",
    "    - Normalizing the input data    \n",
    "    - Remove unnecessary columns (e.g. timestamp, foot and trunk imu data)   \n",
    "    - Saving the preprocessed data into a new data npy file based on the inputs provided for the preprocessing stage (test and train).  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import butter, lfilter, filtfilt\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario parameter settings\n",
    "DATA_PATH = r'dataset'\n",
    "# DATA_PATH = r'C:\\Users\\Elad\\vscode Projects\\Technion\\LBIS_project\\dataset'\n",
    "is_filter = True            # True or False decision variable to filter the IMU data before splitting into windows \n",
    "filter_type = \"causal\"      # causal or non-causal - choose causal for RT applications\n",
    "cutoff = 25                 # cutoff frequency for the filter (Hz)\n",
    "is_normalize = True         # True or False decision variable to normalize the input data after filtering (before windowing) \n",
    "window_size = 200           # Number of samples per window \n",
    "overlap = 100               # Number of samples to overlap between windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_with_label(imu_data: pd.DataFrame, gc_data: pd.DataFrame, window_size=400, overlap=200):\n",
    "    \"\"\" \n",
    "    Perform sliding window on IMU data and extract the last value of GC data as label.\n",
    "    \n",
    "    Parameters:\n",
    "    - imu_data: DataFrame with 12 columns (IMU channels)\n",
    "    - gc_data: DataFrame with 2 columns (labels)\n",
    "    - window_size: Number of samples per window\n",
    "    - overlap: Number of overlapping samples\n",
    "\n",
    "    Returns:\n",
    "    - X_windows: NumPy array of shape (num_windows, 12, window_size)\n",
    "    - y_labels: NumPy array of shape (num_windows, 2)\n",
    "    \"\"\"\n",
    "    step_size = window_size - overlap\n",
    "    X_windows, y_labels = [], []\n",
    "\n",
    "    for start_idx in range(0, imu_data.shape[0] - window_size + 1, step_size):\n",
    "        end_idx = start_idx + window_size\n",
    "        X_windows.append(imu_data.iloc[start_idx:end_idx].values.T)  # (12, window_size)\n",
    "        y_labels.append(gc_data.iloc[end_idx - 1].values)  # Correctly extract both columns\n",
    "    \n",
    "    return np.array(X_windows), np.array(y_labels)\n",
    "\n",
    "def apply_filter(data, filter_type, cutoff=25, fs=200, order=4):\n",
    "    b, a = butter(order, cutoff / (fs / 2), btype='low', analog=False)\n",
    "    return lfilter(b, a, data, axis=0) if filter_type == \"causal\" else filtfilt(b, a, data, axis=0)\n",
    "\n",
    "def plot_filtered_imu(original_df, filtered_df, channel_idx=0):\n",
    "    plt.plot(original_df.iloc[1:500, channel_idx], label=\"Original\", alpha=0.6)\n",
    "    plt.plot(filtered_df.iloc[1:500, channel_idx], label=\"Filtered\", linestyle=\"--\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.title(f\"IMU Channel {original_df.columns[channel_idx]} Before & After Filtering\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preallocate a multidimensional array to store all the data for all trials and all subjects in test/train npy file\n",
    "X_data = np.empty((0, 12, window_size))\n",
    "y_data = np.empty((0, 2))\n",
    "\n",
    "# access all subject folders\n",
    "for subject in os.listdir(DATA_PATH):\n",
    "    # access all csv files in the treadmill folder of the subject\n",
    "    for file in os.listdir(os.path.join(DATA_PATH,  subject, 'treadmill', 'imu')):\n",
    "        # read the imu csv file\n",
    "        if file.endswith('.csv'):\n",
    "            imu_df = pd.read_csv(os.path.join(DATA_PATH, subject, 'treadmill', 'imu', file))\n",
    "            gc_df = pd.read_csv(os.path.join(DATA_PATH, subject, 'treadmill', 'gcRight', file))\n",
    "\n",
    "            # remove unnecessary columns\n",
    "            gc_df = gc_df.drop(columns=[\"ToeOff\"])\n",
    "            imu_df = imu_df.drop(columns=['foot_Accel_X', 'foot_Accel_Y', 'foot_Accel_Z', 'foot_Gyro_X', 'foot_Gyro_Y', 'foot_Gyro_Z', 'trunk_Accel_X', 'trunk_Accel_Y', 'trunk_Accel_Z', 'trunk_Gyro_X', 'trunk_Gyro_Y', 'trunk_Gyro_Z'])\n",
    "\n",
    "            # remove the first and last samples that have no proper label defined (until the first Heel Strike occurance + after the last Toe Off occurance)\n",
    "            gc_df = gc_df.loc[gc_df.index[gc_df[\"HeelStrike\"].gt(0)].min() : gc_df.index[gc_df[\"HeelStrike\"] == 100].max()]\n",
    "            imu_df = imu_df[imu_df[\"Header\"].isin(gc_df[\"Header\"])] # remove the rows that are not in the gc data\n",
    "\n",
    "            # Apply the cosine and sine functions to the HeelStrike column\n",
    "            gc_df['cos_gait_phase'] = np.cos(gc_df['HeelStrike'] * 2 * np.pi / 100)\n",
    "            gc_df['sin_gait_phase'] = np.sin(gc_df['HeelStrike'] * 2 * np.pi / 100)\n",
    "            \n",
    "            # remove header and other columns\n",
    "            gc_df.drop(columns=[\"Header\",\"HeelStrike\"], inplace=True)\n",
    "            imu_df.drop(columns=['Header'], inplace=True)\n",
    "\n",
    "            gc_df.reset_index(drop=True, inplace=True)\n",
    "            imu_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            # Apply a filter to the IMU data (choose between a causal and non-causal filter i.e. with phase or zero phase lag filters)\n",
    "            # filter_type = \"causal\" # or \"non-causal\" - defined in the scenario parameters settings section\n",
    "            filtered_df = pd.DataFrame(apply_filter(imu_df.values, filter_type=filter_type, cutoff=25, order=4), columns=imu_df.columns) if is_filter else imu_df\n",
    "\n",
    "            # Normalize the input data (is_normalize = True or False)\n",
    "            filtered_df = (filtered_df - filtered_df.mean()) / filtered_df.std() if is_normalize else filtered_df\n",
    "\n",
    "            # Split the data into windows (by window size and overlap)\n",
    "            X_windows, y_labels = sliding_window_with_label(filtered_df, gc_df, window_size=window_size, overlap=overlap)\n",
    "            \n",
    "            # Concatenate the data to the multidimensional array\n",
    "            X_data = np.concatenate((X_data, X_windows), axis=0)\n",
    "            y_data = np.concatenate((y_data, y_labels), axis=0)\n",
    "            \n",
    "    # print(f\"The shape of X_windows is: {X_windows.shape}\")\n",
    "    # print(f\"The shape of y_labels is: {y_labels.shape}\")\n",
    "    # print(f\"The first window of X_windows is: {X_windows[0]}\")\n",
    "    # print(f\"The first label of y_labels is: {y_labels[0]}\")\n",
    "    # print(f\"The shape of X_data is: {X_data.shape}\")\n",
    "    # print(f\"The shape of y_data is: {y_data.shape}\")\n",
    "    # plot_filtered_imu(imu_df, filtered_df, channel_idx=0)  # Change channel_idx to plot different channels\n",
    "    # print(gc_df.head())\n",
    "    # print(imu_df.head())\n",
    "\n",
    "# split the data into training and testing sets (80% training and 20% testing, random state = 42 according to tutorial 7) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the testing and training data into npy files\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
